training:
  batch_size: 256
  lr: 0.001
  seed: 42
  val_every_step: 200
  lr_warmup_steps: 2000
  lr_decay_until_steps: 1
  lr_decay_factor: 0.001
  weight_decay: 0.1
  num_steps: 20000
  device: cuda
  amp_precision: bfloat16
  weight_precision: float32
  enable_mixed_precision: true

model:
  num_blocks: 2
  embedding_dim: 0
  mlstm_block:
    mlstm:
      num_heads: 1
  slstm_block: {}
  slstm_at: []
  context_length: 50
  vocab_size: 11

